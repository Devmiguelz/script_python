import requests
from bs4 import BeautifulSoup
import csv
import json
import time

class CinecalidadScraper:
    def __init__(self):
        self.base_url = "https://cinecalidad.bar"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
    
    def extraer_peliculas(self, url=None, pagina=1):
        """
        Extrae informaci√≥n de las pel√≠culas de la p√°gina principal o una p√°gina espec√≠fica
        """
        if url is None:
            if pagina == 1:
                url = self.base_url
            else:
                url = f"{self.base_url}/page/{pagina}/"
        
        try:
            print(f"Scrapeando: {url}")
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Encontrar todos los art√≠culos de pel√≠culas
            peliculas = soup.find_all('article', class_='tposty')
            
            datos_peliculas = []
            
            for pelicula in peliculas:
                try:
                    # Extraer el enlace
                    enlace_tag = pelicula.find('a', class_='absolute')
                    enlace = enlace_tag['href'] if enlace_tag else None
                    
                    # Extraer el t√≠tulo
                    titulo_span = pelicula.find('span', class_='sr-only')
                    titulo = titulo_span.text.strip() if titulo_span else None
                    
                    # Extraer la imagen
                    img_tag = pelicula.find('img')
                    imagen = img_tag['src'] if img_tag else None
                    
                    # Extraer calidad y a√±o
                    calidad_tag = pelicula.find('span', class_='quality')
                    calidad = calidad_tag.text.strip() if calidad_tag else None
                    
                    a√±o_tag = pelicula.find('span', class_='year')
                    a√±o = a√±o_tag.text.strip() if a√±o_tag else None
                    
                    # Extraer descripci√≥n
                    desc_tag = pelicula.find('p', class_='text-sm opacity-70')
                    descripcion = desc_tag.text.strip() if desc_tag else None
                    
                    # Extraer g√©neros
                    generos_container = pelicula.find('p', class_=['absolute', 'bottom-0'])
                    generos = []
                    if generos_container:
                        generos_links = generos_container.find_all('a')
                        generos = [g.text.strip() for g in generos_links]
                    
                    pelicula_data = {
                        'titulo': titulo,
                        'enlace': enlace,
                        'imagen': imagen,
                        'calidad': calidad,
                        'a√±o': a√±o,
                        'descripcion': descripcion,
                        'generos': generos if generos else []
                    }
                    
                    datos_peliculas.append(pelicula_data)
                    
                except Exception as e:
                    print(f"Error al extraer pel√≠cula: {e}")
                    continue
            
            print(f"‚úì {len(datos_peliculas)} pel√≠culas extra√≠das de la p√°gina {pagina}")
            return datos_peliculas
            
        except Exception as e:
            print(f"Error al hacer scraping: {e}")
            return []
    
    def extraer_multiples_paginas(self, num_paginas=3):
        """
        Extrae pel√≠culas de m√∫ltiples p√°ginas
        """
        todas_peliculas = []
        
        for pagina in range(1, num_paginas + 1):
            print(f"\n{'='*60}")
            print(f"P√°gina {pagina} de {num_paginas}")
            print('='*60)
            
            peliculas = self.extraer_peliculas(pagina=pagina)
            todas_peliculas.extend(peliculas)
            
            # Pausa entre p√°ginas para ser respetuoso
            if pagina < num_paginas:
                time.sleep(2)
        
        return todas_peliculas

    def guardar_json(self, datos, archivo='peliculas_cinecalidad.json'):
        """
        Guarda los datos en un archivo JSON
        """
        if not datos:
            print("No hay datos para guardar")
            return
        
        with open(archivo, 'w', encoding='utf-8') as f:
            json.dump(datos, f, ensure_ascii=False, indent=2)
        
        print(f"‚úì Datos guardados en '{archivo}'")
    
    def mostrar_peliculas(self, datos, limite=5):
        """
        Muestra las pel√≠culas extra√≠das en la consola
        """
        print(f"\n{'='*80}")
        print(f"PEL√çCULAS ENCONTRADAS (Mostrando {min(limite, len(datos))} de {len(datos)})")
        print('='*80)
        
        for i, pelicula in enumerate(datos[:limite], 1):
            print(f"\n{i}. {pelicula['titulo']}")
            print(f"   A√±o: {pelicula['a√±o']} | Calidad: {pelicula['calidad']}")
            print(f"   G√©neros: {pelicula['generos']}")
            print(f"   URL: {pelicula['enlace']}")
            if pelicula['descripcion']:
                desc = pelicula['descripcion'][:100] + "..." if len(pelicula['descripcion']) > 100 else pelicula['descripcion']
                print(f"   Descripci√≥n: {desc}")

# Ejemplo de uso
if __name__ == "__main__":
    scraper = CinecalidadScraper()
    
    print("üé¨ SCRAPER DE CINECALIDAD")
    print("="*80)
    
    # Opci√≥n 1: Extraer pel√≠culas de una sola p√°gina
    print("\nüìÑ Extrayendo pel√≠culas de la p√°gina principal...")
    peliculas = scraper.extraer_peliculas()
    
    # Mostrar resultados
    scraper.mostrar_peliculas(peliculas)
    
    # Guardar en JSON
    scraper.guardar_json(peliculas)
    
    # Opci√≥n 2: Extraer de m√∫ltiples p√°ginas
    print("\n" + "="*80)
    respuesta = input("\n¬øQuieres extraer de m√∫ltiples p√°ginas? (s/n): ").lower()
    
    if respuesta == 's':
        try:
            num_paginas = int(input("¬øCu√°ntas p√°ginas quieres scrapear? (1-79): "))
            if 1 <= num_paginas <= 79:
                print(f"\nüìö Extrayendo pel√≠culas de {num_paginas} p√°ginas...")
                todas_peliculas = scraper.extraer_multiples_paginas(num_paginas=num_paginas)
                scraper.mostrar_peliculas(todas_peliculas, limite=15)
                scraper.guardar_json(todas_peliculas, f'peliculas_{num_paginas}_paginas.json')
                print(f"\nüìä Total de pel√≠culas extra√≠das: {len(todas_peliculas)}")
            else:
                print("‚ö†Ô∏è N√∫mero de p√°ginas fuera de rango (1-79)")
        except ValueError:
            print("‚ö†Ô∏è Por favor ingresa un n√∫mero v√°lido")
    
    print("\n‚úÖ Scraping completado exitosamente!")